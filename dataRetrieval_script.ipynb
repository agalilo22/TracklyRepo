{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8112c174-aaa6-4d6d-ac97-4a853966968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to Ganache successfully!\n",
      "✅ Connected to Smart Contract at 0xF7bA4959568973D4c9CB36678D809D277F6D1276\n",
      "\n",
      "Total Records on blockchain (initial check): 65\n",
      "\n",
      "CSV Data Preview for Upload:\n",
      "  device_id data_type    data_value\n",
      "0    PKG001  Location      New York\n",
      "1    PKG001    Status    In Transit\n",
      "2    PKG002  Location       Chicago\n",
      "3    PKG002    Status  At Warehouse\n",
      "4    PKG003    Status     Delivered\n",
      "\n",
      "--- Sending CSV data to Blockchain ---\n",
      "✅ Data Stored: Location - New York, Timestamp: 2025-06-19 16:08:38, Txn Hash: 49279913a0bd1cb32ac796109e65a10c918401156754d9238a0573b226f714b7\n",
      "✅ Data Stored: Status - In Transit, Timestamp: 2025-06-19 16:08:38, Txn Hash: 79304e2cf5e4258b0d346fece1f9c7d58c081604da0798718ba2ebc95eb732fd\n",
      "✅ Data Stored: Location - Chicago, Timestamp: 2025-06-19 16:08:39, Txn Hash: 6e896d267f040c975b23f54c6a525948fec1a4ecfa7626c1d7168384b6606b63\n",
      "✅ Data Stored: Status - At Warehouse, Timestamp: 2025-06-19 16:08:39, Txn Hash: 17d292768b4e94558658b1d90c730a9c4c89ad7c545987bc44bdfa3ba24b479e\n",
      "✅ Data Stored: Status - Delivered, Timestamp: 2025-06-19 16:08:40, Txn Hash: 1b0fe858d8a14f09021e11c5e1ec76d643c92305214f945464481ae10fa33f50\n",
      "--- Finished sending CSV data ---\n",
      "\n",
      "--- Starting Week 6: Data Retrieval and Processing ---\n",
      "Total IoT records stored for retrieval: 70\n",
      "\n",
      "DataFrame from Blockchain (first 5 records):\n",
      "            timestamp device_id data_type  data_value\n",
      "0 2025-05-28 08:54:25   TEST001  Location    New York\n",
      "1 2025-05-28 08:55:02   TEST001  Location    New York\n",
      "2 2025-05-28 08:55:02    PKG001  Location    New York\n",
      "3 2025-05-28 08:55:03    PKG001    Status  In Transit\n",
      "4 2025-05-28 08:55:04    PKG002  Location     Chicago\n",
      "\n",
      "--- Preprocessing Retrieved Data ---\n",
      "Missing values before handling:\n",
      "timestamp         0\n",
      "device_id         0\n",
      "data_type         0\n",
      "data_value        0\n",
      "numeric_value    66\n",
      "dtype: int64\n",
      "\n",
      "DataFrame after Preprocessing (first 5 records):\n",
      "            timestamp device_id data_type  data_value  numeric_value\n",
      "0 2025-05-28 08:54:25   TEST001  Location    New York            0.0\n",
      "1 2025-05-28 08:55:02   TEST001  Location    New York            0.0\n",
      "2 2025-05-28 08:55:02    PKG001  Location    New York            0.0\n",
      "3 2025-05-28 08:55:03    PKG001    Status  In Transit            0.0\n",
      "4 2025-05-28 08:55:04    PKG002  Location     Chicago            0.0\n",
      "\n",
      "Total IoT records in DataFrame: 70\n",
      "\n",
      "--- All Stored Records in DataFrame ---\n",
      "             timestamp device_id data_type    data_value  numeric_value\n",
      "0  2025-05-28 08:54:25   TEST001  Location      New York            0.0\n",
      "1  2025-05-28 08:55:02   TEST001  Location      New York            0.0\n",
      "2  2025-05-28 08:55:02    PKG001  Location      New York            0.0\n",
      "3  2025-05-28 08:55:03    PKG001    Status    In Transit            0.0\n",
      "4  2025-05-28 08:55:04    PKG002  Location       Chicago            0.0\n",
      "..                 ...       ...       ...           ...            ...\n",
      "65 2025-06-19 08:08:38    PKG001  Location      New York            0.0\n",
      "66 2025-06-19 08:08:38    PKG001    Status    In Transit            0.0\n",
      "67 2025-06-19 08:08:39    PKG002  Location       Chicago            0.0\n",
      "68 2025-06-19 08:08:39    PKG002    Status  At Warehouse            0.0\n",
      "69 2025-06-19 08:08:40    PKG003    Status     Delivered            0.0\n",
      "\n",
      "[70 rows x 5 columns]\n",
      "------------------------------\n",
      "\n",
      "✅ Cleaned IoT data saved successfully as cleaned_iot_data.csv\n",
      "\n",
      "--- Next Steps for GitHub Upload ---\n",
      "1. Save your current Python script (.py) or Jupyter Notebook (.ipynb).\n",
      "2. Locate the generated CSV file: cleaned_iot_data.csv in your project directory.\n",
      "3. Navigate to your GitHub repository in your web browser: https://github.com/agalilo22/FIMS\n",
      "4. Click 'Add file' -> 'Upload files'.\n",
      "5. Drag and drop or select your Python script/Jupyter Notebook and the 'cleaned_iot_data.csv' file.\n",
      "6. Add a concise commit message (e.g., 'Feat: Week 6 Data Retrieval & Processing').\n",
      "7. Click 'Commit changes' to save your work to the repository.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from web3 import Web3\n",
    "import numpy as np # Import numpy as it's used for data processing\n",
    "\n",
    "# Connect to local Ganache blockchain\n",
    "ganache_url = \"http://127.0.0.1:7545\"  # Update to 8545 if needed\n",
    "web3 = Web3(Web3.HTTPProvider(ganache_url))\n",
    "\n",
    "# Verify connection\n",
    "if web3.is_connected():\n",
    "    print(\"✅ Connected to Ganache successfully!\")\n",
    "else:\n",
    "    print(\"❌ Connection failed. Ensure Ganache is running.\")\n",
    "    exit()\n",
    "\n",
    "# Load the smart contract\n",
    "# IMPORTANT: Replace with your CURRENTLY DEPLOYED contract address from Remix.\n",
    "# Example: contract_address = \"0xd8b934580fcE35a11B58C6D73aDeE468a2833fa8\"\n",
    "# The address 0xF7bA4959568973D4c9CB36678D809D277F6D1276 was previously used.\n",
    "# Please ensure you use the one currently deployed in your Ganache instance.\n",
    "contract_address = \"0xF7bA4959568973D4c9CB36678D809D277F6D1276\" # <<< VERIFY THIS ADDRESS\n",
    "# Ensure all 'false' and 'true' are 'False' and 'True' in your ABI\n",
    "abi = [\n",
    "  {\n",
    "\t\t\"inputs\": [],\n",
    "\t\t\"stateMutability\": \"nonpayable\",\n",
    "\t\t\"type\": \"constructor\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"anonymous\": False,\n",
    "\t\t\"inputs\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"indexed\": False,\n",
    "\t\t\t\t\"internalType\": \"uint256\",\n",
    "\t\t\t\t\"name\": \"timestamp\",\n",
    "\t\t\t\t\"type\": \"uint256\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"indexed\": False,\n",
    "\t\t\t\t\"internalType\": \"string\",\n",
    "\t\t\t\t\"name\": \"packageId\",\n",
    "\t\t\t\t\"type\": \"string\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"indexed\": False,\n",
    "\t\t\t\t\"internalType\": \"string\",\n",
    "\t\t\t\t\"name\": \"dataType\",\n",
    "\t\t\t\t\"type\": \"string\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"indexed\": False,\n",
    "\t\t\t\t\"internalType\": \"string\",\n",
    "\t\t\t\t\"name\": \"dataValue\",\n",
    "\t\t\t\t\"type\": \"string\"\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t\t\"name\": \"DataStored\",\n",
    "\t\t\"type\": \"event\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"inputs\": [],\n",
    "\t\t\"name\": \"MAX_ENTRIES\",\n",
    "\t\t\"outputs\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"uint256\",\n",
    "\t\t\t\t\"name\": \"\",\n",
    "\t\t\t\t\"type\": \"uint256\"\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t\t\"stateMutability\": \"view\",\n",
    "\t\t\"type\": \"function\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"inputs\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"uint256\",\n",
    "\t\t\t\t\"name\": \"\",\n",
    "\t\t\t\t\"type\": \"uint256\"\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t\t\"name\": \"dataRecords\",\n",
    "\t\t\"outputs\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"uint256\",\n",
    "\t\t\t\t\"name\": \"timestamp\",\n",
    "\t\t\t\t\"type\": \"uint256\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"string\",\n",
    "\t\t\t\t\"name\": \"packageId\",\n",
    "\t\t\t\t\"type\": \"string\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"string\",\n",
    "\t\t\t\t\"name\": \"dataType\",\n",
    "\t\t\t\t\"type\": \"string\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"string\",\n",
    "\t\t\t\t\"name\": \"dataValue\",\n",
    "\t\t\t\t\"type\": \"string\"\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t\t\"stateMutability\": \"view\",\n",
    "\t\t\"type\": \"function\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"inputs\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"uint256\",\n",
    "\t\t\t\t\"name\": \"index\",\n",
    "\t\t\t\t\"type\": \"uint256\"\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t\t\"name\": \"getRecord\",\n",
    "\t\t\"outputs\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"uint256\",\n",
    "\t\t\t\t\"name\": \"\",\n",
    "\t\t\t\t\"type\": \"uint256\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"string\",\n",
    "\t\t\t\t\"name\": \"\",\n",
    "\t\t\t\t\"type\": \"string\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"string\",\n",
    "\t\t\t\t\"name\": \"\",\n",
    "\t\t\t\t\"type\": \"string\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"string\",\n",
    "\t\t\t\t\"name\": \"\",\n",
    "\t\t\t\t\"type\": \"string\"\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t\t\"stateMutability\": \"view\",\n",
    "\t\t\"type\": \"function\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"inputs\": [],\n",
    "\t\t\"name\": \"getTotalRecords\",\n",
    "\t\t\"outputs\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"uint256\",\n",
    "\t\t\t\t\"name\": \"\",\n",
    "\t\t\t\t\"type\": \"uint256\"\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t\t\"stateMutability\": \"view\",\n",
    "\t\t\"type\": \"function\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"inputs\": [],\n",
    "\t\t\"name\": \"owner\",\n",
    "\t\t\"outputs\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"address\",\n",
    "\t\t\t\t\"name\": \"\",\n",
    "\t\t\t\t\"type\": \"address\"\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t\t\"stateMutability\": \"view\",\n",
    "\t\t\"type\": \"function\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"inputs\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"string\",\n",
    "\t\t\t\t\"name\": \"_packageId\",\n",
    "\t\t\t\t\"type\": \"string\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"string\",\n",
    "\t\t\t\t\"name\": \"_dataType\",\n",
    "\t\t\t\t\"type\": \"string\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"internalType\": \"string\",\n",
    "\t\t\t\t\"name\": \"_dataValue\",\n",
    "\t\t\t\t\"type\": \"string\"\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t\t\"name\": \"storeData\",\n",
    "\t\t\"outputs\": [],\n",
    "\t\t\"stateMutability\": \"nonpayable\",\n",
    "\t\t\"type\": \"function\"\n",
    "\t}\n",
    "]\n",
    "contract = web3.eth.contract(address=contract_address, abi=abi)\n",
    "web3.eth.default_account = web3.eth.accounts[0] # Set default sender (first Ganache account, must be owner)\n",
    "print(f\"✅ Connected to Smart Contract at {contract_address}\")\n",
    "\n",
    "# --- Test contract by calling getTotalRecords (initial check) ---\n",
    "try:\n",
    "    total_records_initial = contract.functions.getTotalRecords().call()\n",
    "    print(f\"\\nTotal Records on blockchain (initial check): {total_records_initial}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error calling getTotalRecords: {e}\")\n",
    "    print(\"Please ensure contract is deployed correctly and chain synced. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# --- Store dummy IoT data if no records exist (for testing purposes) ---\n",
    "if total_records_initial == 0:\n",
    "    print(\"\\nNo records found. Storing some dummy data to populate the contract...\")\n",
    "    try:\n",
    "        txn = contract.functions.storeData(\"INITIAL001\", \"Temp\", \"25.0C\").transact({\n",
    "            'from': web3.eth.default_account,\n",
    "            'gas': 1000000\n",
    "        })\n",
    "        receipt = web3.eth.wait_for_transaction_receipt(txn)\n",
    "        if receipt.status == 1:\n",
    "            # Decode event for the timestamp\n",
    "            event_logs = contract.events.DataStored().process_receipt(receipt)\n",
    "            if event_logs:\n",
    "                dummy_timestamp = event_logs[0].args.timestamp\n",
    "                readable_dummy_timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(dummy_timestamp))\n",
    "                print(f\"✅ Dummy data stored on blockchain! Timestamp: {readable_dummy_timestamp}\")\n",
    "            else:\n",
    "                print(\"✅ Dummy data stored on blockchain! (Timestamp not found in event logs)\")\n",
    "        else:\n",
    "            print(\"❌ Dummy data transaction failed!\")\n",
    "            print(receipt)\n",
    "            exit()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error storing initial dummy data: {e}\")\n",
    "        print(\"Please ensure your default account is the contract owner.\")\n",
    "        exit()\n",
    "    # Update total_records after storing dummy data\n",
    "    total_records_initial = contract.functions.getTotalRecords().call()\n",
    "    print(f\"Total Records on blockchain (after initial dummy data): {total_records_initial}\")\n",
    "\n",
    "# --- Load IoT sensor data from CSV and populate blockchain (if desired, or use existing data) ---\n",
    "# This section assumes you want to add more data from a CSV.\n",
    "# If your contract is already populated and you just want to retrieve, you can comment this out.\n",
    "try:\n",
    "    df_upload = pd.read_csv(\"formatted_logistics_data.csv\")\n",
    "    print(\"\\nCSV Data Preview for Upload:\")\n",
    "    print(df_upload.head())\n",
    "\n",
    "    # Function to send IoT data to blockchain\n",
    "    def send_iot_data(package_id, data_type, data_value):\n",
    "        \"\"\"Sends IoT data to the deployed smart contract and prints its timestamp.\"\"\"\n",
    "        try:\n",
    "            txn = contract.functions.storeData(package_id, data_type, data_value).transact({\n",
    "                'from': web3.eth.default_account,\n",
    "                'gas': 3000000\n",
    "            })\n",
    "            receipt = web3.eth.wait_for_transaction_receipt(txn)\n",
    "\n",
    "            if receipt.status == 1:\n",
    "                event_logs = contract.events.DataStored().process_receipt(receipt)\n",
    "                if event_logs:\n",
    "                    timestamp = event_logs[0].args.timestamp\n",
    "                    readable_timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(timestamp))\n",
    "                    print(f\"✅ Data Stored: {data_type} - {data_value}, Timestamp: {readable_timestamp}, Txn Hash: {receipt.transactionHash.hex()}\")\n",
    "                else:\n",
    "                    print(f\"✅ Data Stored: {data_type} - {data_value}, Txn Hash: {receipt.transactionHash.hex()} (Timestamp not found in event logs)\")\n",
    "            else:\n",
    "                print(f\"❌ Data Stored: {data_type} - {data_value}, Transaction failed! Txn Hash: {receipt.transactionHash.hex()}\")\n",
    "                print(receipt)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error storing data for {package_id}: {e}\")\n",
    "\n",
    "    print(\"\\n--- Sending CSV data to Blockchain ---\")\n",
    "    for _, row in df_upload.iterrows():\n",
    "        send_iot_data(str(row[\"device_id\"]), str(row[\"data_type\"]), str(row[\"data_value\"]))\n",
    "        time.sleep(0.5)  # Shorter delay to prevent flooding transactions\n",
    "    print(\"--- Finished sending CSV data ---\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"\\n'formatted_logistics_data.csv' not found. Skipping CSV data upload.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error processing CSV for upload: {e}\")\n",
    "\n",
    "\n",
    "# --- Week 6: Data Retrieval and Processing ---\n",
    "print(\"\\n--- Starting Week 6: Data Retrieval and Processing ---\")\n",
    "\n",
    "# Get the total number of stored records (re-fetch after any uploads)\n",
    "try:\n",
    "    total_records = contract.functions.getTotalRecords().call()\n",
    "    print(f\"Total IoT records stored for retrieval: {total_records}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error getting total records for retrieval: {e}\")\n",
    "    exit()\n",
    "\n",
    "if total_records == 0:\n",
    "    print(\"No records to retrieve from the blockchain. Exiting processing.\")\n",
    "    exit()\n",
    "\n",
    "# Fetch all stored IoT data and structure it in a DataFrame\n",
    "data_list = []\n",
    "for i in range(total_records):\n",
    "    try:\n",
    "        # Call getRecord to retrieve the data\n",
    "        record = contract.functions.getRecord(i).call()\n",
    "        # record will be a tuple: (timestamp, packageId, dataType, dataValue)\n",
    "        data_list.append({\n",
    "            \"timestamp\": record[0],\n",
    "            \"device_id\": record[1], # Column name for DataFrame, corresponds to contract's packageId\n",
    "            \"data_type\": record[2],\n",
    "            \"data_value\": record[3]\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error retrieving record at index {i}: {e}\")\n",
    "        print(\"Skipping this record.\")\n",
    "        continue # Continue to the next record even if one fails\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Convert timestamp (Unix seconds) to readable datetime format\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\")\n",
    "\n",
    "# Display first few records of the raw DataFrame\n",
    "print(\"\\nDataFrame from Blockchain (first 5 records):\")\n",
    "print(df.head())\n",
    "\n",
    "# --- Data Preprocessing ---\n",
    "print(\"\\n--- Preprocessing Retrieved Data ---\")\n",
    "\n",
    "# Extract numeric values from 'data_value' where applicable\n",
    "# Robust regex for numbers, including decimals and scientific notation.\n",
    "df[\"numeric_value\"] = pd.to_numeric(\n",
    "    df[\"data_value\"].astype(str).str.extract(r'([+\\-]?\\d*\\.?\\d+(?:[Ee][+\\-]?\\d+)?)')[0],\n",
    "    errors='coerce' # Convert non-numeric values to NaN\n",
    ")\n",
    "\n",
    "# Identify missing values after numeric extraction\n",
    "print(f\"Missing values before handling:\\n{df.isnull().sum()}\")\n",
    "\n",
    "# Handle missing values in 'numeric_value' column\n",
    "# FIX APPLIED HERE: Avoid chained assignment with inplace=True\n",
    "# Replace NaNs in 'numeric_value' with 0 as per instructions for minor missing values.\n",
    "df[\"numeric_value\"] = df[\"numeric_value\"].fillna(0) # Corrected line\n",
    "\n",
    "# Display cleaned data with new 'numeric_value' column\n",
    "print(\"\\nDataFrame after Preprocessing (first 5 records):\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# --- Verify all stored data (optional, but good for inspection) ---\n",
    "print(f\"\\nTotal IoT records in DataFrame: {len(df)}\")\n",
    "if len(df) > 0:\n",
    "    print(\"\\n--- All Stored Records in DataFrame ---\")\n",
    "    # You can print the whole DataFrame if it's not too large\n",
    "    # print(df.to_string()) # Use .to_string() for full view without truncation\n",
    "    # Or just print a summary\n",
    "    print(df)\n",
    "    print(\"-\" * 30)\n",
    "else:\n",
    "    print(\"No records to display after processing.\")\n",
    "\n",
    "\n",
    "# --- Save to CSV ---\n",
    "output_csv_filename = \"cleaned_iot_data.csv\"\n",
    "df.to_csv(output_csv_filename, index=False)\n",
    "\n",
    "print(f\"\\n✅ Cleaned IoT data saved successfully as {output_csv_filename}\")\n",
    "\n",
    "print(\"\\n--- Next Steps for GitHub Upload ---\")\n",
    "print(\"1. Save your current Python script (.py) or Jupyter Notebook (.ipynb).\")\n",
    "print(f\"2. Locate the generated CSV file: {output_csv_filename} in your project directory.\")\n",
    "print(\"3. Navigate to your GitHub repository in your web browser: https://github.com/agalilo22/FIMS\")\n",
    "print(\"4. Click 'Add file' -> 'Upload files'.\")\n",
    "print(\"5. Drag and drop or select your Python script/Jupyter Notebook and the 'cleaned_iot_data.csv' file.\")\n",
    "print(\"6. Add a concise commit message (e.g., 'Feat: Week 6 Data Retrieval & Processing').\")\n",
    "print(\"7. Click 'Commit changes' to save your work to the repository.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade3cfa4-9fc5-40f0-9753-d841c24b6c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
